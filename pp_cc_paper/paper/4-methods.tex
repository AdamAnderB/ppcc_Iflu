
\subsection{Participants}
The recruitment of 50 L1 Italian L2 English speakers was managed through Prolific \citep{Palan_2018}. For the purposes of this study, we did not ask about 'native status' \citep{Brown_Tusmagambet_Rahming_Tu_DeSalvo_Wiener_2023} ; instead we define an L1 Italian speaker as someone who self-identified via Prolific as a fluent Italian speaker, whose first and primary language is Italian. Because Italian is spoken all over the world, we further specified that the participants must born in Italy to control for linguistic variation. All participants also reported fluency in English as an L2. All participants were required to score an 80\% or higher on the LexITA \citep{Amenta2021}, which estimates Italian vocabulary size and was presented entirely in Italian (and thus requiring participants to be able to read and understand Italian). An additional 29 potential participants were rejected due to failing initial calibration requirements (i.e., three removed for LexITA scores below 80\% accuracy, 25 removed for failed headphone-checks \citep{milne_2021} and/or failed web-camera-checks). To ensure data quality and maximize retained participants, three median absolute deviations (MAD) from median square root transformed reaction time was calculated as the standard for removal for battery tasks \citep{Leys_2013}. Of the participants who remained, three were removed for being below the three MAD \citep{Leys_2013} range in overall speech cue sensitivity. After removal, 47 participants' (age: $\mu$ = 34.5 years, \textit{sd} = 9.6 years), data were retained for analysis. In total, the tasks reported here took participants approximately 30 minutes to complete. All participants were paid for their time. The study was approved by the authors' Institutional Review Board.

\subsection{Materials}

The primary task (2x2 visual world paradigm design) consisted of 28 pairs of trisyllabic words taken from \cite{Sulpizio_McQueen_2012} that were selected as targets and competitor pairs (see Gorilla experiment spreadsheets). The original audio files from \cite{Sulpizio_McQueen_2012}recorded at 44 kHz (16 bit resolution, mono) were shared with us. The target-competitor pairs were each made up of two real words that are segmentally identical for the first two syllables. However, the stress of the two words varied between second syllable (penultimate) and first syllable stress (antepenultimate). That is, the word pairs are suprasegmentally contrastive and segmentally identical for the first two syllables, which is the focus of the analyses below. For each of these word-pairs, the segments diverged at the third syllable (e.g., calata vs. calamo). Each set of visual stimuli consisted of a target (e.g., calata), a competitor (e.g., calamo), and two distractors (e.g., remoto and remoro). The distractors were always a target-competitor pairing as well to ensure balanced looks between visual stimuli. That is, a participant could not tell what the correct target-competitor pairing was just by viewing the visual stimuli pairs and simply ignoring the non-segmentally similar items. Comparisons between first and second syllable measures and can be found in table \ref{tab:acoustics}, which shows our measurements and \cite{Sulpizio_McQueen_2012}'s results. All syllables were hand-annotated and automation scripts were used to extract acoustic information \citep{qi_textgrid_maker, dicanio_vowel_acoustics}. Aggregate values were calculated by averaging within stress type and syllable for pitch, amplitude, and spectral tilt. However, duration was calculated by averaging the difference between min and max times of each segment in the text\_grid\_extractor.rmd (see our OSF repository for scripts). All materials and tasks are made freely available on Gorilla. 


\begin{table}[ht]
\centering
\caption{Predictor statistics for penultimate and antepenultimate first and second syllables}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} lcccccc}
\hline
\textbf{Study} & \textbf{Stress} & \textbf{Predictor} & \textbf{1st vowel} & \textbf{2nd vowel} &\textbf{t value} & \textbf{p value}\\
\hline
Our study & Penultimate & Amplitude (dB)       & .09 & .06 & 5.18  & $<$ .01\\
     &           & Pitch (f0)           & 245 & 217 & 6.99  & $<$ .01\\
     &             & Duration (ms)        & 67 & 162 & -20.84 & $<$ .01\\
     &             & Spectral tilt   & .1 & .1 & 0.33  & $>$.05 \\
 & Antepenultimate & Amplitude (dB)      & .08 & .05 & 7.51  & $<$ .01\\
     &             & Pitch (f0)          & 235 & 182 & 13.17 & $<$ .01\\
     &             & Duration (ms)        & 138 & 71 & 13.11 & $<$ .01\\
     &             & Spectral tilt   & .1 & .09 & 8.26  & $<$ .01\\
\hline
Sulpizio and\\ McQueen (2012) &Penultimate & Amplitude (dB)    & .09 & .06   & 4.42 & $<$ .01\\
       &           & Pitch (f0)         & 238  & 204 & 4.43 & $<$ .01\\
       &           & Duration (ms)      & 75 & 180   & -18.20 & $<$ .01\\
       &           & Spectral tilt &.3 & .3 & $<$ 1  & $>$.05\\
& Antepenultimate  & Amplitude (dB)     & .09  & .04 & 8.03  & $<$ .01\\
       &           & Pitch (f0)         &  219 & 177 & 10.54  & $<$ .01\\
       &           & Duration (ms)      & 165  & 81  & 16.14  & $<$ .01\\
       &           & Spectral tilt &  .7  & .03  & 5.19  & $<$ .01\\
\hline
\end{tabular*}
\label{tab:acoustics}
\end{table}

\subsection{Procedure}

The experiment was hosted on Gorilla and distributed through Prolific; participants took part on a personal computer in a setting that met the requirements of the experiment (i.e., good lighting and little to no background noise). To ensure this, before beginning the experiment, participants first consented and then were required to do four additional screening tasks: LexITA, a basic hearing check which ensured that audio could be heard, a dichotic pitch task \citep{milne_2021} which could only be passed with high quality headphones, and nine-point eye-tracking calibration \citep{bramlett_wiener_24-AOW}. If the participants passed all four screenings, the experiment would begin. The experiment consisted of three parts: individual differences tasks, the eye-tracking experiment, and an Italian speech rating task that is part of a different study and not reported here. In total, there were eight individual difference tasks (including LexITA, which was also used to screen participants). Other than the LexITA, all tasks were presented in English. The order of tasks was always fixed, which is shown in \ref{fig:task_structure}. 

\begin{figure}[H]
  \centering
  \includegraphics[width=1\linewidth]{visuals/task_structure.jpg}
  \caption{Task structure: All tasks were presented in the same order from beginning (left) to end (right). Note that LexITA is both a measure and a screening task.}
  \label{fig:task_structure}
\end{figure}

After consenting and passing the initial four screening tasks, participants began the digit span task. The digit span task presented a series of digits, each displayed for 500 ms and separated by a 250 ms fixation cross. Participants were asked to use their mouse to select the sequence in the same order on a digital number pad. The task began with two digits and had a staircase design with sequence length increasing by one after each correct trial and decreasing by one after each incorrect trial. The task ended after 13 trials. 

The four battery tasks consisted of AX discrimination tasks which tested participants' sensitivity to pitch, risetime, duration, and formant contrasts. For each task (36 trials per task), a sound was presented followed by a 250 ms fixation cross and then a second. Participants were asked to use the `z' and `m' keys to indicate whether the sounds were the same or different. For all battery tasks, a continuum of 50 stimuli was used \citep{Kachlicka_Saito_Tierney_2019}. 10 of these were selected at various distances (15-55). The distance between stimuli and same/different trials was presented randomly.

For the eye-tracking task, eye-fixations were captured using WebGazer.js \citep{Papoutsaki} implemented in Gorilla \citep{Anwyl-Irvine_2019}. All audio stimuli and word pairings were taken from \cite{Sulpizio_McQueen_2012}. All 64 experimental and distractor words were shown in lower-case letters balanced across the four quadrants. Visual stimuli were placed maximally apart to increase the distance between areas of interest. Distractor and experimental trials were presented in random order. Like \cite{Sulpizio_McQueen_2012}, each trial began with a fixation cross that was displayed for 500 ms. Next, the audio stimuli and visual stimuli were presented simultaneously. After the audio file finished playing ($\mu$ = 110 ms, \textit{sd} = 51 ms), visual stimuli stayed on the screen for 500 ms for the participant to select the word that they had been presented. Before the experiment, \cite{Sulpizio_McQueen_2012} did a read-aloud familiarization task with the participants, but zero words were unknown to any participant. For this reason (and to shorten the overall experiment length) we decided to remove the familiarization task due to the relatively high frequency of the words.

After completion of the eye-tracking task, participants then took part in the English LexTALE task as well as the autism-spectrum quotient questionnaire (AQ) \citep{Baron-Cohen2001}(cite). Both of these tasks were purposefully put after the eye-tracking task to mitigate negative effects on task performance \citep{Chang_2024}. In the English LexTALE task, participants were shown a fixation cross for 500 ms and then a word or non-word was displayed for 2000 ms. Participants were asked to use the keys 'j' and 'k' to decide whether the presented letters formed a real word or non-word within the allotted time \cite{lemhofer2012introducing}. 

The AQ (cite) consisted of 50 multiple choice questions, each with four options: ``strongly disagree", ``disagree", ``agree", and ``strongly agree"). The direction of high tendency scoring was balanced across questions (i.e., ``strongly agree" and ``strongly disagree" were marked as high tendency equally). The 50 questions covered five areas (10 questions per area): social skills, attention switching, attention to detail, communication, imagination. The internal consistency of the questions, as measured by Cronbach’s alpha, was xxx (Cronbach, \href{https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-022-00439-w\#ref-CR17}{1951}).



\subsection{Data analysis}

All analyses were carried out in R (version xxx; R Core Team,xxx) with a 0.05 alpha level. The individual difference measures were calculated so that each participant had a single score for each task. For the digit span task, each participant's max digit correct was used as a measure of working memory capacity. For the four battery tasks, hits and misses for each trial were scored and sensitivity to each contrast type was then calculated using d-prime. The scores for both Italian LexITA and English LexTALE were calculated by taking the mean of correct and incorrect responses (non-responses were ignored). Lastly, the AQ was scored using Baron-Cohen et al.'s rubric: autistic-like behavior was scored as 1 (irrespective of “slightly” or “definitely” response); non-autistic-like behavior was scored as 0 (irrespective of "slightly" or “definitely” response). Participants were given a total score (0 to 50); scores of 32 or greater represented what Baron-Cohen et al. call “a useful cutoff for distinguishing individuals who have clinically significant levels of autistic traits” (\href{https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-022-00439-w\#ref-CR5}{2001}, 15).

For eye-tracking data removal, eye-fixations outside the possible screen area were removed. As suggested in \cite{bramlett_wiener_24-AOW}, quadrants were defined by the origin to maximize signal retention. Both fixation and frame rate data removal were based on \cite{bramlett_wiener_24-AOW}. Fixations at the beginning of the trials were normally distributed from the center at the beginning trials along both the x and y axes. Eye-fixations with face confirmation below 50\% certainty were removed. We retained approximately 96.14\% of eye-fixations (3.86\% data loss). Unlike other recent online web-based eye-tracking experiments we did not remove any data for low frame rate. We set a minimal frame rate for participants to 5 fps \citep{Vos_2017}. However, no participants qualified for removal based on their median frame rate. 


