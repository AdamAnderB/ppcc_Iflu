\subsection{Individual differences in language processing}

Individual differences in language prediction have become a focal point of recent psycholinguistic research, revealing substantial variability in how people process and anticipate linguistic input. These differences are shaped by a variety of cognitive and linguistic factors, and provide insights into the underlying mechanisms of language acquisition and processing \citep{Huettig2016,Li2023,Kidd2018}. In the present two-part exploratory study, we probe four areas of individual differences research known to affect prosody perception: working memory, auditory sensitivity, lexical proficiency, and autism spectrum quotient. Specifically, we examine how behavior on eight individual difference tasks predicts eye-movements during real-time prediction and processing of Italian lexical stress.

\subsubsection{Working memory}
Working memory has been shown to significantly influence anticipatory language processing. \cite{Huettig2016} found that individuals with greater working memory capacity and faster processing speed are better at predicting upcoming linguistic information, as evidenced by their performance in visual world paradigms. Similarly, \cite{Li2023} demonstrated through eye-tracking and ERP studies that working memory plays a crucial role in language prediction, affecting how listeners process and anticipate spoken words. Working memory consistently comes up as a meaningful cognitive factor across studies from a variety of languages \citep{mchaney_et_al_2021_workingmemory,goss_2014,hadar_2016}. 

\subsubsection{Auditory Sensitivity}
Auditory sensitivity is a critical factor in language processing, particularly within one's native language (L1). Studies have shown that robust auditory processing is essential for effective language comprehension and prediction. For example, \cite{goss_2014} explored the relationship between acoustic pitch sensitivity and working memory in Japanese pitch accent perception, finding that both higher working memory capacity and greater pitch sensitivity significantly enhance pitch accent perception. This underscores the interplay between cognitive abilities and linguistic proficiency within one's L1.Further, \cite{Pajak_2014} demonstrated that sensitivity to specific acoustic cues, such as duration and sibilance, varies depending on the linguistic environment, highlighting the gradient nature of auditory sensitivity. 

This suggests that individuals are attuned to the specific auditory features prevalent in their native language. \cite{Bradlow_1994} found that English speakers with higher sensitivity to formant frequencies exhibited better word recognition performance. Similarly, \cite{Hazan_2000} showed that auditory discrimination abilities in L1 are linked to more accurate phoneme perception and language comprehension. These findings collectively indicate that heightened auditory sensitivity, including pitch, duration, risetime, and formants, plays a crucial role in native language processing and prediction.

In summary, auditory sensitivity, including pitch, duration, risetime, and formants, plays a crucial role in native language processing and prediction. Individuals with heightened auditory sensitivity are better equipped to predict and process linguistic information, underscoring the importance of auditory abilities in L1 comprehension.

\subsubsection{Lexical proficiency}
Lexical proficiency, both in the L1 and L2, contributes to individual differences in language processing and prediction \citep{Diependaele2013,Yap2012}. For example, \citep{Kukona2016} found that real-time prediction and inhibition are modulated by their proficiency and literacy in both languages. Theoretically, the more proficient a speaker is, the larger their lexicon will be, which in turn results in a larger competitor space as more lexical candidates are activated. Interestingly, bilinguals co-activate between languages during the process of word recognition \citep{kroll1997lexical,dijkstra2002architecture,marian2003competing}, which suggests that if someone has experience with more than one language this may either positively or negatively affect L1 language word recognition. For an extreme example, \cite{cutler2007dutch}'s suggests that Dutch speakers are better at English stress than English native speakers, which is corroborated in \cite{Pajak_2014} who found that experience with a cue in one language transfers to a new language gradiently. 

\subsubsection{Autism spectrum quotient}
Finally, we examine autism spectrum quotient (AQ: \cite{Baron-Cohen2001}). Research on prosody perception by individuals diagnosed with autism spectrum disorder is a growing sub-field  \citep[see ][]{Grice2023,Paul2005,McCann2003}. For example, the demands of word recognition for pitch sensitive words have been suggested to cause difficulty for those with autism spectrum disorder \citep{schelinski2020speech}. In Contrast, \cite{grossman2023relationship} found that the so-called disadvantageous for pitch sensitivity for those with ASD are actually modulated by more general cognitive factors and that pitch sensitivity was similar to neuro-typical participants. Moreover, the literature on auditory sensitivity for those with autism spectrum disorder is mixed, suggesting varied sensitivity to sound \citep{Kuiper2019,Stiegler2010}. We add to recent work \cite{Sinagra2022} exploring whether variability in prosody perception may, in part, be accounted for by autism spectrum quotient (AQ). 

To summarize, we carry out an exploratory individual differences study that examines how working memory, sensitivity to pitch, duration, risetime, and formants, lexical proficiency in an L1 and L2, and autism spectrum quotient predict the real-time processing of spoken Italian tri-syllabic words with differing stress patterns.

\subsection{Spoken word recognition and lexical stress}

Listeners use incoming acoustic-phonetic cues to disambiguate between potential lexical competitors. For example, when an English speaker hears \textipa{/mE/}, they will activate both \textit{metal} and \textit{melon} among other potential candidates \citep{Marslen1980}. As the second syllable unfolds, listeners will begin to disambiguate the two. In addition to these cohort competitors, rhyme competitors begin to compete with similar endings words even when onsets differ (e.g., metal and kettle) \citep{Allopenna_1998}. The visual world paradigm, which we use in the present study, offers insight into the time course of word recognition. It is especially valuable in that fine-grained eye movements show early prediction and competition among cohort and rhyme competitors \citep{Allopenna_1998}.

In the present study, we are interested in continuous activation of lexical competitors at the suprasegmental level. For example, Mandarin speakers use tonal information including f0 movement, duration, and amplitude \cite[e.g.,][]{Zhang2022} to distinguish between otherwise segmentally identical competitors \cite{Lee2008}: /m\=a/ and /m\'a/ are segmentally identical but tonally contrastive. Evidence exists from a classic lexical categorization task \citep{fox_1985},  to more recent eye-tracking studies which demonstrate the time course of tonal word recognition \citep{zou_2022}. Similar tonal competition effects have been demonstrated in Cantonese \citep{qin_2022,Nixon2016}, Pitch-accent users like Japanese speakers also make use of f0, duration, and amplitude information in real-time in order to recognize otherwise segmentally identical words \citep{goss_2014,Cutler1999,Ito2024}.

Lexical tone and pitch-accent, however, are both heavily separable from a word's segmental information; vowels can remain the same while tone categories and pitch-accent patterns change \citep{Zeng2017}. Tones and pitch-accent tend to also be acoustically reliable; the primary cue is f0 height or f0 contour \citep{goss_2014}.  Stress serves as an interesting counter to tone and pitch-accent given just how variable stress can be. The stressed syllable of a word is the syllable that is the 'strongest' \citep{sluijter1996spectral}, but what is perceived as the 'strongest' syllable varies across languages \citep{Cutler1988}. Some languages primarily use duration for stress, while others use pitch or spectral tilt. The reliability of cues across languages also varies with more predictable languages like Spanish and less predictable stress patterns like that of Catalan and English \citep{ortega_2011, beckman_1994}. That is, for some languages like Spanish, stress can be decoupled from the syllable having little to no effect on the vowel itself \citep{ortega_2011}. However, in languages like English and Italian, this is not possible. Stress changes also directly affect vowel quality, pitch, and/or duration of the syllable. In terms of word recognition, the role of lexical stress is equally complex \citep{cutler2001voornaam,Reinisch2010}

\subsubsection{Italian lexical stress}
Italian listeners are sensitive to lexical stress and make use of stress cues before segmentally disambiguating information becomes available in the process of word recognition \cite{Tagliapietra2005, Sulpizio_McQueen_2012}. Importantly, Italian stressed vowels differ from unstressed vowels in terms of pitch, duration, intensity, and spectral tilt. \citep{Maturi1998}. \cite{Sulpizio_McQueen_2012} used the visual world paradigm to record eye movements to written tri-syllabic Italian words while spoken Italian words were played. Although these words can have stress on any of the three syllables, the two most common stress patterns are penultimate and antepenultimate e.g., CAlata vs. caLAmo (FOOTNOTE: capital letters indicate stress). Penultimate stress words (second syllable stressed) are the most frequent in the Italian lexicon (roughly 80\% of all Italian tri-syllabic words. The antepenultimate (first syllable stressed) stress pattern is much less frequent (18\%) but still more frequent than final syllable stress words (2\%) \citep{thornton_1997}. The authors recruited 22 Italian university students (mean age 26.3) and recorded their eye movements as they looked to words shown on screen.

\cite{Sulpizio_McQueen_2012} found that Italian speakers used their abstract knowledge of lexical stress and considered penultimate stress to be the default. Italian listeners used stress cues at an early stage-at the second syllable before segmental disambiguation- of word recognition (like Dutch speakers in \cite{Reinisch2010}). Primarily amplitude was used by listeners but only when detecting antepenultimate stress (the non-default stress pattern tested). While there was no difference in fixations toward target or competitors over the time course of word recognition between stress pattern. Eye-fixations toward the target began to become greater than competitor fixations during the second syllable and not before. The recognition of penultimate and antepenultimate words did not show differences across the syllables. However, once accounting for acoustic cues, it was found that eye-fixations toward the penultimate target increased for antepenultimate words that have higher amplitude. This same fixation behavior was not observed for penultimate counterparts, \cite{Sulpizio_McQueen_2012} interpret this result to mean that words are asssumed to have penultimate stress by default due to their overwhelming frequency. 

We set out to replicate \cite{Sulpizio_McQueen_2012}  while also extending it to include an exploratory study into individual differences of Italian stress perception. It may be that stress is processed variably across adults as it is in children \citep[e.g.,][]{Colombo2014} and patients with language disorders \citep[e.g.,][]{Cappa1997}. It may also be that Sulpizio and McQueen's relatively homogeneous sample of university students is not representative of behavior found among a larger adult pool of Italian speakers. We add to the relatively small (but growing) body of work looking at individual differences in prosody perception \citep[e.g.,][]{Roy2017,Bishop2017,Lameris2023}. Here we explore how individual differences modulate the integration of complex suprasegmental cues like lexical stress in real-time.


\subsection{The current study: Individual differences in predictive eye-movements}

We replicate and extend the first experiment from \cite{Sulpizio_McQueen_2012}, which examined the time course of Italian word recognition for tri-syllabic Italian words. We carry out this replication with two goals in mind. First, we believe replications are necessary for the field to progress \citep{Rakosi2017}, and inherently have value \citep{Kobrock2023}. We also believe replicating an in-person eye-tracking study carried out in a university setting with a new population of (non-university student) adults recruited online, using web cameras, is a worthy pursuit \citep{Prystauka_Altmann_Rothman_2023}. We make all our materials, data, and code available as part of our replication in the interest of promoting open and transparent science. Because we were provided the original audio stimuli from \cite{Sulpizio_McQueen_2012}, our replication also serves an opportunity to reanalyze the acoustics and confirm their results (i.e., increase researcher degrees of freedom \cite{Corretta2023}.

Second, we carry out an exploratory study to gain a better understanding of the role of individual differences in prosody perception, particularly what individual difference predictors can help account for real-time lexical stress prediction and processing. While the findings of \cite{Sulpizio_McQueen_2012} are in themselves worthy of replication, Italian word stress is a relatively understudied area and ripe for a study on individual differences as we do not fully understand how listeners vary in their behavior.  \cite{Maturi1998} claim that vowel amplitude serves as the main stress cue (corroborated by \cite{Sulpizio_McQueen_2012}) while \cite{Alfano2006} and \cite{Alfano2009} claim vowel duration is the main stress cue while \cite{Tagliapietra2005} claim Italian listeners make use of both vowel duration and intensity to identify the stressed syllable. This variation could be due to the different methods used to test stress perception and/or the different participants tested such that some listeners rely more on one cue while other listeners rely more on another cue, i.e., individual differences in language processing \citep{Yu2019,Kidd2018}.

Here, we aim to first replicate \cite{Sulpizio_McQueen_2012}'s overall group finding with over double the participants tested (Sulpizio and McQueen: 22; our replication: 47), using an internet-based recruitment of non-university student adults, and an web-based eye-tracking paradigm \citep{Vos_2017}. We therefore formed the following four research question for the replication: 1) What are the primary acoustic cues for each stress type? 2) To what extent do penultimate and antepenultimate stress words differ in the time course of word recognition? 3) Is there a bias in target fixations for penultimate stress words due their higher frequency in the lexicon? 4) To what extent do specific acoustic cues predict recognition of penultimate and antepenultimate stress words? 

In addition to these replication questions, we ask two additional exploratory questions that parallel the second and fourth replication research questions and extend them to individual differences. 1) To what extent do individual differences affect penultimate and antepenultimate stress words recognition? 2) To what extent do individual differences account for specific acoustic cues used during the recognition of penultimate and antepenultimate stress words?

\subsubsection{Predictions}

With respect to these two exploratory questions, we predict that individuals with greater working memory will show earlier predictions? \citep[e.g.,][]{Traxler2009}

Auditory sensitivity prediction - do better on these, identify prosody earlier/faster

Lexical proficiency prediction....  Like their study, in the case of English experience on Italian stress perception, higher amounts of English could make first syllable stress easier due to the higher occurrence of first syllable stress in English. Similarly, English experience could cause confusion due to variation in stress cues across languages.

Austim spectrum quotient prediction - higher AQ worse prosody and might interact with other tasks 
