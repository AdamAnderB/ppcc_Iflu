\subsection{Spoken word recognition and lexical stress}

Listeners use incoming acoustic-phonetic cues to disambiguate between potential lexical competitors in real-time. For example, when hearing the English syllable \textipa{/mE/}, listeners activate \textit{metal} and \textit{melon} among other potential \textipa{/mE/}--initial lexical candidates \citep{Marslen1980}. As the second syllable unfolds, listeners will begin to disambiguate the two words. In addition to cohort competitors, words that share the same rhyme but different onsets (e.g., metal and kettle) are also activated \citep{Allopenna_1998}.

In the present visual world paradigm study \citep{Tanenhaus_Spivey-Knowlton_Eberhard_Sedivy_1995}, we are interested in the activation of lexical competitors at the suprasegmental level. For example, Mandarin speakers use tonal information that includes fundamental frequency (F0) or pitch, duration, and amplitude to distinguish between otherwise segmentally identical competitors \citep{Lee2008, Zhang2022, fox_1985}: /m\=a/ and /m\'a/. Evidence from Mandarin and Cantonese eye-tracking studies demonstrate how tonal competitors are activated during the time course of tonal word recognition \citep{zou_2022, qin_2022, Nixon2016}. Japanese speakers also make use of f0, duration, and amplitude information in real-time in order to recognize otherwise segmentally identical pitch-accent contrastive words \citep{goss_2014, Cutler1999, Ito2024}.

Lexical tone and pitch-accent, however, are both heavily separable from a word's segmental information; vowels can remain the same while tone categories and pitch-accent patterns change \citep{Zeng2017}. Tones and pitch-accent tend to also be acoustically reliable; the primary cue is f0 height or f0 contour \citep{goss_2014}. Among suprasegmentals, stress serves as an interesting deviation from the clear separation that tone and pitch-accent provide, given just how variable stress can be. The stressed syllable of a word is the syllable that is the 'strongest' \citep{sluijter1996spectral}, yet what is perceived as the 'strongest' syllable varies across languages \citep{Cutler1988}. Some languages primarily use duration for stress, while others use pitch or spectral tilt. The reliability of cues across languages also varies from more predictable languages like Spanish to less predictable languages like Catalan and English \citep{ortega_2011, beckman_1994}. That is, for some languages like Spanish, stress can be decoupled from the syllable having little to no effect on the vowel itself \citep{ortega_2011}, like tone or pitch accent. However, in languages like English and Italian, this is not possible. Stress changes also directly affect vowel quality, pitch, and or duration of the syllable. In terms of word recognition, the role of lexical stress is equally complex \citep{cutler2001voornaam, Reinisch2010}

\subsubsection{Italian lexical stress}
Italian listeners are sensitive to lexical stress during word recognition and make use of stress cues before segmentally disambiguating information becomes available \citep{Tagliapietra2005, Sulpizio_McQueen_2012}. Importantly, stressed Italian vowels differ from unstressed vowels in terms of pitch, duration, intensity, and spectral tilt, which refers to the relative intensity distribution across different frequency bands, with a focus on how energy shifts from lower to higher frequencies in the speech signal \citep{Maturi1998}. \cite{Sulpizio_McQueen_2012} used the visual world paradigm to record eye movements to written trisyllabic Italian words while spoken Italian words were played (Experiment 1). Although trisyllabic Italian words can have stress on any of the three syllables, the two most common stress patterns are antepenultimate and penultimate, for example, CAlata vs. caLAmo (capital letters indicate stress). The antepenultimate (first syllable) stress pattern is much less frequent (18\%) than penultimate (second syllable) stressed words (roughly 80\% of all Italian trisyllabic lexicon), but still more frequent than final syllable stressed words (2\%) \citep{thornton_1997}. 

\cite{Sulpizio_McQueen_2012} recruited 32 Italian university students (age: $\mu$ = 26.3 years, $\sigma$ = 6.2 years) and recorded their eye movements as they looked to words shown on screen, including a target and competitor that differed in stress during the first two syllables and the last syllable. Two other distractors, which differed segmentally from the target and competitor, were also shown on the screen. Italian listeners used stress cues during the second syllable, that is, before segmental disambiguation, to identify the target. These results corroborated previous Dutch research on the time-course of stress integration for word recognition \citep{Reinisch2010}. \cite{Sulpizio_McQueen_2012} found that amplitude was used by listeners but only when detecting antepenultimate stress (the non-default stress pattern for trisyllabic words). Importantly, listeners made use of the decrease in amplitude from the first vowel to the second vowel in antepenultimate words. The authors found no difference in looks to antepenultimate and penultimate target words across the syllables. However, once accounting for acoustic cues, it was found that eye-fixations toward the penultimate targets increased for antepenultimate words that lacked the decrease in amplitude. Finally, the authors also found a significant correlation between looks and spectral tilt during the second syllable for antepenultimate words. As the difference between spectral tilt from the first vowel to the second vowel decreased, participants looked less to antepenultimate targets. In other words, because antepenultimate words showed a significant difference in spectral tilt from the first vowel to the second vowel (whereas penultimate words did not), participants looked less to antepenultimate stressed words if this difference was reduced (or not present). Taken together, \cite{Sulpizio_McQueen_2012} argued for an asymmetry in trisyllabic Italian lexical processing: antepenultimate stress words are recognized using incoming acoustic cues, while penultimate stress words are recognized by default (based on listeners' abstract knowledge that penultimate stressed words are much more frequent in Italian). 


\subsection{Individuals differ in their language processing behavior}

Recent psycholinguistic research has revealed substantial variability in how listeners process and anticipate linguistic input. These differences are shaped by a variety of cognitive and linguistic factors, and provide insights into the underlying mechanisms of language acquisition and processing \citep{Huettig2016, Kidd2018}. Here, we present a close replication of \cite{Sulpizio_McQueen_2012}'s in-person eye-tracking study, transitioning from in-person to web-based methods. We also extend their study by probing four areas of individual differences research known to affect prosody perception: auditory sensitivity, lexical proficiency, working memory, and autism spectrum quotient. We explore how responses from eight behavioral tasks predict eye-movements during real-time predicting and processing of trisyllabic Italian words.

\subsubsection{Auditory sensitivity}
Research into auditory processing is broad and interdisciplinary, including work on child L1 acquisition \citep{benasich2002infant}, adult L2 acquisition \citep{lengeris2010effect, kempe2012individual}, children and adults with language disorders \citep{goswami2013impaired} among other disciplines. Yet, there is a fairly broad consensus that reliable detection of auditory spectral and temporal cues is essential for prediction and processing of lower-level speech, especially at the prosodic level. 

Take tone languages, which use fundamental frequency for lexical contrasts, as an example. Listeners with congenital amusia ('tone deafness') struggle more in word discrimination and identification for tonally contrastive words than their neurotypical peers \citep{nan_2010, zhu2023tone}. Deficits in pitch perception extend to the processing of lexical tones, highlighting the shared processing mechanisms for general pitch cues and linguistic pitch cues. For pitch-accent languages like Japanese, similar findings are reported. \cite{goss_2014} explored the relationship between acoustic pitch sensitivity in Japanese pitch accent perception. The authors found that pitch sensitivity significantly predicted pitch accent perception accuracy.

For individuals with aphasia, impaired processing of risetime---how quickly the amplitude of a sound rises to
its peak level---and phoneme identification both significantly impact higher-level language processing in speech comprehension \citep{Kries2023}. Similar results are supported by correlations between risetime detection and syllable level phonological skills, suggesting the importance of sensitivity to amplitude in word recognition \citep{Hamalaine2005}. 

Moreover, auditory sensitivity to cues can affect both the L1 and L2. For example, \cite{cutler2007dutch} suggest that L1 Dutch speakers—who rely on consistent acoustic markers such as pitch, duration, and intensity to signal lexical stress—are better at identifying syllable stress in English than native English speakers, possibly because Dutch stress patterns are acoustically more salient and predictable than those in English. In contrast, L1 English speakers may rely more on contextual or lexical information to resolve stress ambiguities. This finding is corroborated by \cite{Pajak2014}, who found that experience with an acoustic cue in one language transfers to a new language in a gradient manner. Similarly, \cite{wienergoss} demonstrate that L1 Mandarin listeners outperform L1 Japanese listeners on a Japanese pitch accent discrimination task despite not speaking the language. The authors argue that greater auditory sensitivity to pitch, stemming from learning Mandarin’s four lexical tone categories, benefited the L1 Mandarin listeners in this task.

Here we build on this previous literature and carry out an exploratory individual differences study that examines how auditory sensitivity to pitch, duration, risetime, and amplitude are associated with Italian stress perception and prediction based on lexical stress.

\subsubsection{Lexical proficiency}
Lexical proficiency, both in the L1 and L2, contributes to individual differences in language processing and prediction \citep{Diependaele2013, Yap2012}. For example, \cite{Kukona2016} found that real-time prediction and inhibition are modulated by proficiency and literacy in both languages. Theoretically, the more proficient a speaker is, the larger their lexicon will be, which in turn results in a larger competitor space as more lexical candidates are activated. Interestingly, bilinguals co-activate both languages during the process of word recognition \citep{kroll1997lexical, dijkstra2002architecture, marian2003competing}, which suggests that if someone has experience with more than one language this may either positively (e.g., L1 Dutch speakers are better at English stress identification) or negatively (increased competition) affect word recognition. One study of note is \cite{primativo2013bilingual}, which found that English-Italian bilinguals' vocabulary size influences speed and reading accuracy of Italian words, particularly accuracy of stress assignment. Although the present study is concerned with perception (rather than production), \cite{primativo2013bilingual}'s findings suggest there may be a link between the size of the lexicon and sensitivity to subtle prosodic variations. \cite{misra2012} highlight how bilingual proficiency modulates prediction during language comprehension, with increased proficiency allowing bilinguals to better manage competition between languages, thus affecting predictive processing. We extend work in this domain to examine whether L1 and L2 lexical knowledge affects Italian stress prediction and processing.

\subsubsection{Working memory}
Working memory has been shown to significantly influence anticipatory language processing. \cite{Huettig2016} found that individuals with greater working memory capacity and faster processing speed are better at predicting upcoming linguistic information, as evidenced by their performance in visual world eye-tracking studies. This type of prediction involves leveraging broader linguistic context to anticipate upcoming words or structures. In contrast, \cite{otten2009} found that while both high and low working memory capacity individuals can predict upcoming words, low working memory capacity individuals experience greater difficulty processing unexpected information. Prediction, however, can occur at various levels of processing, including spoken word recognition. Within word recognition prediction occurs as part of a continuous and interactive system, where acoustic, phonological, and lexical information are dynamically integrated in real time, which is the interest of the current study. To recognize words, listeners rely on phonological cues and suprasegmental features to anticipate which word is being uttered. For example, \cite{hadar_2016} showed that increasing working memory load slows down spoken word recognition (as reflected in delayed eye movements), as participants took longer to process spoken words when their working memory was taxed. Similarly, \cite{mchaney_et_al_2021_workingmemory} found that individuals with higher working memory capacity were better at learning new speech sound categories.

\cite{goss_2014} extended this idea to suprasegmental features, testing whether working memory predicts the perception of lexical pitch accent in Japanese. They found evidence for a role of verbal working memory in acoustic pitch sensitivity, though only for categorization of a specific accent pattern. Here we extend research in this domain to examine whether working memory serves as a reliable predictor of real-time trisyllabic Italian word processing, focusing on its role in integrating suprasegmental cues like pitch and duration within lexical representations.


\subsubsection{Autism spectrum quotient}
Finally, we examine autism spectrum quotient (AQ: \cite{Baron-Cohen2001}). Research on prosody perception by individuals diagnosed with autism spectrum disorder is a growing sub-field \citep[see ][]{Grice2023, Paul2005, McCann2003}. For example, the demands of word recognition for pitch-sensitive words have been suggested to cause difficulty for those with autism spectrum disorder \citep{schelinski2020speech}. In contrast, \cite{grossman2023relationship} found that the so-called disadvantageous for pitch sensitivity for those with autism are actually modulated by more general cognitive factors (e.g., attention) and that stress sensitivity was similar for neurotypical participants. Moreover, the literature on auditory sensitivity for those with autism spectrum disorder is mixed, suggesting varied sensitivity to sound \citep{Kuiper2019, Stiegler2010}. \cite{haesen2011review}'s review suggests that individuals with autism spectrum disorder may exhibit enhanced pitch sensitivity but struggle with the integration of complex auditory cues, such as those involved in speech perception, which could contribute to variability in stress perception across participants. We add to this growing body of work and explore whether variability in Italian stress perception may, in part, be accounted for by autism spectrum quotient (AQ).



\subsection{The current study: Individual differences in predictive eye-movements}
Because stress is processed variably across adults as it is in children \citep[e.g.,][]{Colombo2014} and participants with language disorders \citep[e.g.,][]{Cappa1997}, it may be that \cite{Sulpizio_McQueen_2012}'s relatively homogeneous sample of university students is not representative of behavior found among a larger adult pool of Italian speakers. In this study, we embrace both 'daytime science'—the systematic, hypothesis-driven replication of previous findings—and 'nighttime science'—the exploratory investigation into individual differences. We set out to rigorously test established theories while remaining open to new insights \citep{Yanai2020}.

We carry out this replication with two goals in mind. First, we believe replications are necessary for the field to progress \citep{Rakosi2017} and are intrinsically valuable \citep{Kobrock2023}. We also believe replicating an in-person eye-tracking study carried out in a university setting with a new population of adults recruited online, using web cameras, is a worthy pursuit \citep{Prystauka_Altmann_Rothman_2023}. Our replication constitutes a 'close replication' defined as an effort to reproduce the original study's design and methodology, while accommodating necessary adjustments to fit new contexts\citep{mcmanus2022replication}. We maintain the original experimental design including the authors' original stimuli, while adapting it to an online format which inherently samples from a different population than the WEIRD populations typically recruited in university settings. Although our statistical methods differ—using more conservative approaches (e.g., generalized linear mixed-effects models and LASSO regression) instead of ANOVA—this reduces the likelihood of false positives, as fewer statistical tests are conducted, making any replicated findings more robust and unified while maintaining the same intent of the original analyses. Because we were provided the original audio stimuli from \cite{Sulpizio_McQueen_2012}, our replication also serves as an opportunity to reanalyze the acoustics and confirm their results, i.e., increase researcher degrees of freedom \citep{Corretta2023}. We make materials, data, and code available as part of our replication in the interest of promoting open and transparent science.

Second, we carry out an exploratory study to gain a better understanding of the role of individual differences in prosody perception, particularly what individual difference predictors can help account for the real-time predicting and processing of lexical stress. While the findings of \cite{Sulpizio_McQueen_2012} are in themselves worthy of replication, Italian word stress is a relatively understudied area and ripe for a study on individual differences as we do not fully understand how listeners vary in their behavior. \cite{Maturi1998} claim that vowel amplitude serves as the main stress cue (corroborated by \cite{Sulpizio_McQueen_2012}) while \cite{Alfano2006} and \cite{Alfano2009} claim vowel duration is the main stress cue while \cite{Tagliapietra2005} claim Italian listeners make use of both vowel duration and intensity to identify the stressed syllable. This variation could be due to the different methods used to test stress perception and/or the different participants tested such that some listeners rely more on one cue while other listeners rely more on another cue. We add to the relatively small---but growing---body of work looking at individual differences in prosody perception \citep[e.g.,][]{Roy2017, Bishop2017, Lameris2023, Sinagra2022, Kidd2018}.

Here, we aim to first replicate \cite{Sulpizio_McQueen_2012}'s Experiment 1 overall group finding with a larger sample size (\cite{Sulpizio_McQueen_2012}: N = 32; our replication: N = 47), using an internet-based recruitment of adults, and a web-based eye-tracking paradigm \citep{Vos_2017}. We therefore formed the following four research questions for the replication:

1) What are the primary acoustic cues for each stress type? 

2) To what extent do antepenultimate and penultimate stressed words differ in their time course of word recognition? 

3) Is there a bias in target fixations for penultimate stress words due to their higher frequency in the lexicon? 

4) To what extent do specific acoustic cues predict recognition of antepenultimate and penultimate stressed words? 

In addition to these replication questions, we ask one additional exploratory question: 

5) To what extent do individual differences account for specific acoustic cues used during the recognition of antepenultimate and penultimate stressed words?

\subsubsection{Predictions guiding our exploratory individual differences study}
To better guide our exploratory study, we predict the following results: 

Participants with greater auditory sensitivity for any of the four cues (pitch, duration, risetime, formants) will identify prosodic cues more quickly and accurately, leading to faster and more precise predictions of lexical stress. This is due to their ability to use fine-grained acoustic details effectively \citep{nan_2010, goss_2014,mcmurray_2008}. We specifically expect pitch, risetime, and duration to play roles given their contribution to Italian stress \citep{Tagliapietra2005, Alfano2006,Alfano2009,Maturi1998}.

Participants with greater L1 Italian proficiency will look to penultimate targets faster and predict penultimate stress earlier; this prediction is in line with \cite{Sulpizio_McQueen_2012} given participants' greater awareness of the Italian lexicon and its distributional characteristics. Participants with greater L2 English proficiency may look to antepenultimate targets faster and earlier due to this stress pattern's prevalence in English \citep{cutler2007dutch}. However, this proficiency could also cause confusion due to cross-linguistic differences in stress cues, potentially leading to delayed predictions \citep{primativo2013bilingual}. 

Participants with greater working memory capacity will show earlier target predictions during the processing of Italian lexical stress, as their enhanced ability to maintain and manipulate linguistic information facilitates anticipatory processing during the process of word recognition \citep{Traxler2009, Huettig2016}.

Participants with higher autism spectrum quotients (AQ) may have greater difficulty with prosody perception, resulting in slower predictions of lexical stress \citep{schelinski2020speech, grossman2023relationship}. Higher AQ scores are expected to pattern with less efficient eye-movement patterns and poorer integration of stress cues during real-time processing.


Finally, we test for two-way interactions between auditory sensitivity and the acoustic cues. Our predictions here are two-fold. One, we expect that individuals with greater sensitivity to a cue will use that cue when it is most informative for a particular stress pattern. Two, the use of acoustic cues will be attenuated for the more common stress type (a penultimate stress word bias). That is, duration decreases from vowel one to vowel two for antepenultimate stressed words but increases from vowel one to vowel two for penultimate stressed words. Individuals with greater sensitivity to duration will look to antepenultimate words with longer vowel one durations. However, this effect will be attenuated in penultimate stressed words.

